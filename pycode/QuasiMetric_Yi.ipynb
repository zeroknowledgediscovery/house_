{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subWordSet(input_string):\n",
    "    length = len(input_string)\n",
    "    return set([input_string[i: j + 1] for i in range(length) for j in range(i, length)])\n",
    "\n",
    "\n",
    "def get_weightedJac(R1, R2, \n",
    "                    get_weight=None, *, \n",
    "                    symbol_weight_map=None, \n",
    "                    verbose=False):\n",
    "    \"\"\"\n",
    "    Calculate the weighted subword Jaccard distance between two formatted medical histories.\n",
    "    \"\"\"\n",
    "    if get_weight is None:\n",
    "        get_weight = lambda seq: 1\n",
    "    \n",
    "    if get_weight == 'linear':\n",
    "        get_weight = lambda seq: np.array([symbol_weight_map[s] for s in seq]).sum()\n",
    "    \n",
    "    S1 = get_subWordSet(R1)\n",
    "    S2 = get_subWordSet(R2)\n",
    "    union = S1.union(S2)\n",
    "    intersection = S1.intersection(S2)\n",
    "    \n",
    "    if verbose:\n",
    "        print('S1: {}'.format(S1))\n",
    "        print('S2: {}'.format(S2))\n",
    "        print('Union: {}'.format(union))\n",
    "        print('Intersection: {}'.format(intersection))\n",
    "    \n",
    "    weight_union = 0\n",
    "    weight_intersection = 0\n",
    "    for seq in union:\n",
    "        weight = get_weight(seq)\n",
    "        weight_union += weight\n",
    "        if seq in intersection:\n",
    "            weight_intersection += weight\n",
    "    \n",
    "    return 1.0 - float(weight_intersection) / float(weight_union)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_weightedJac(R1, R2, \n",
    "                        get_weight=None, *,\n",
    "                        end_time=None,\n",
    "                        symbol_weight_map=None, \n",
    "                        verbose=False):\n",
    "    \"\"\"\n",
    "    Let R1 and R2 be two medical histories.\n",
    "    The function calculate weighted subword Jaccard distance\n",
    "    between R1[:end_time] and R2[:end_time],\n",
    "    for all end_time in range(1, min(len(R1), len(R2))).\n",
    "    \n",
    "    The reason for designing this function is that\n",
    "    Jaccard distance between R1[:end_time], R2[:end_time])\n",
    "    can be calcucated dynamically using memoization.\n",
    "    (search dynamic programming for more detail on\n",
    "    memoization).\n",
    "    \"\"\"\n",
    "    if get_weight is None:\n",
    "        get_weight = lambda seq: 1\n",
    "    \n",
    "    if get_weight == 'linear':\n",
    "        get_weight = lambda seq: np.array([symbol_weight_map[s] for s in seq]).sum()\n",
    "    \n",
    "    if end_time == None:\n",
    "        end_time = min(len(R1), len(R2))\n",
    "        \n",
    "    union = {}\n",
    "    weight_union = 0\n",
    "    weight_intersection = 0\n",
    "    distances = []\n",
    "    \n",
    "    for time in range(end_time):\n",
    "        \n",
    "        for t in range(time + 1):\n",
    "            word1 = R1[time - t: time + 1]\n",
    "            word2 = R2[time - t: time + 1]\n",
    "            \n",
    "            if word1 in union:\n",
    "                if union[word1][0] == '2':\n",
    "                    union[word1][0] = 'b' # 'b' is a shorthand for both\n",
    "                    weight_intersection += union[word1][1]\n",
    "            else:\n",
    "                weight = get_weight(word1)\n",
    "                union[word1] = ['1', weight]\n",
    "                weight_union += weight\n",
    "                \n",
    "            if word2 in union:\n",
    "                if union[word2][0] == '1':\n",
    "                    union[word2][0] = 'b'\n",
    "                    weight_intersection += union[word2][1]\n",
    "            else:\n",
    "                weight = get_weight(word2)\n",
    "                union[word2] = ['2', weight]\n",
    "                weight_union += weight\n",
    "        \n",
    "        \n",
    "        distance = 1.0 - float(weight_intersection) / float(weight_union)\n",
    "        distances.append(distance)\n",
    "        \n",
    "        if verbose:\n",
    "            print('record length = {}'.format(time))\n",
    "            # print('\\tunion = {}'.format(union))\n",
    "            print('\\tweight of union = {}'.format(weight_union))\n",
    "            print('\\tweight of intersection = {}'.format(weight_intersection))\n",
    "            print('\\tweighted subword Jaccard distance = {}\\n'.format(distance))\n",
    "            \n",
    "    return np.array(distances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on get_all_weightedJac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol_weight_map = {'1': 1, '2': 2}\n",
    "R1 = '1222111212221'\n",
    "R2 = '12121222111121'\n",
    "# get_all_weightedJac(R1, R2, get_weight='linear', symbol_weight_map=symbol_weight_map, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_weightedJac_matrices(histories, *,\n",
    "                                 get_weight=None,\n",
    "                                 symbol_weight_map=None,\n",
    "                                 end_time=None,\n",
    "                                 verbose=False):\n",
    "    \n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "\n",
    "    length = np.array([len(h) for h in histories]).min()\n",
    "    \n",
    "    if end_time is None:\n",
    "        end_time = length\n",
    "        \n",
    "    if end_time > length:\n",
    "        raise Exception('end_time must be smaller or equal to the length of shortest history!')\n",
    "    \n",
    "    num_histories = len(histories)\n",
    "    matrices = np.zeros((end_time, num_histories, num_histories))\n",
    "    for i in range(num_histories):\n",
    "        for j in range(i + 1, num_histories):\n",
    "            dist = get_all_weightedJac(histories[i], histories[j], \n",
    "                                       get_weight=get_weight, \n",
    "                                       end_time=end_time, \n",
    "                                       symbol_weight_map=symbol_weight_map)\n",
    "            for t in range(len(dist)):\n",
    "                matrices[t][i][j] = dist[t]\n",
    "                matrices[t][j][i] = dist[t]\n",
    "    \n",
    "    return matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get_neighborhood_prevalence function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_neighborhood_prevalence(dist, epsilon, histories, time):\n",
    "    \n",
    "    \"\"\"\n",
    "    For all i in range(len(histories)), \n",
    "    calculate the prevalence of histories[i][time] \n",
    "    in the epsilon-neighborhood of histories[i][: time-1].\n",
    "    \"\"\"\n",
    "    \n",
    "    dim = len(dist)\n",
    "    neighborhood_prevalence = np.zeros(dim)\n",
    "    for i in range(dim):\n",
    "        count = 0\n",
    "        target = histories[i][time]\n",
    "        indices = np.arange(dim)[dist[i] <= epsilon]\n",
    "        \n",
    "        for idx in indices:\n",
    "            if histories[idx][time] == target:\n",
    "                neighborhood_prevalence[i] += 1.\n",
    "        \n",
    "        neighborhood_prevalence[i] /= float(len(indices))    \n",
    "    \n",
    "    return neighborhood_prevalence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterative approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_modifiedJac(matrix, prob):\n",
    "    \n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    \n",
    "def get_distance(histories, *, \n",
    "                 epsilon, \n",
    "                 prevalence,\n",
    "                 get_weight=None, \n",
    "                 symbol_weight_map=None, \n",
    "                 end_time=None, \n",
    "                 verbose=False, \n",
    "                 initial_dist=None):\n",
    "    \n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    \n",
    "    length = np.array([len(h) for h in histories]).min()\n",
    "    \n",
    "    if end_time is None:\n",
    "        end_time = length\n",
    "        \n",
    "    if end_time > length:\n",
    "        raise Exception('end_time must be smaller or equal to the length of shortest history!')\n",
    "    \n",
    "    get_all_weightedJac_matrices(histories, \n",
    "                                 get_weight=get_weight,\n",
    "                                 symbol_weight_map=symbol_weight_map,\n",
    "                                 end_time=end_time,\n",
    "                                 verbose=False)\n",
    "    \n",
    "    num_histories = len(histories)\n",
    "    prob = np.array([prevalence[history[0]] for history in histories])\n",
    "    cur_dist = initial_dist\n",
    "    next_dist = np.zeros((num_histories, num_histories))\n",
    "    \n",
    "    for t in range(end_time - 1):\n",
    "        Jac = matrices[t]\n",
    "        modified_Jac = get_modified_Jac(Jac, prob)\n",
    "        prob = get_neighborhood_prevalence(modified_Jac, epsilon, history, t + 1)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate dummy history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = 50 # Let us assume that histories are of uniform length\n",
    "num_histories = 20\n",
    "num_diseases = 10\n",
    "prevalence = np.array([50, 1, .5, .5, .5, .2, .2, .1, .1, 0.05])\n",
    "prevalence = prevalence / prevalence.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The no-brainer way\n",
    "with which I probably will give a man breast cancer or so... (or a woman prostate cancer, which is even less likely)\n",
    "\n",
    "**Please help me come up more sensable ways of generating dummy medical histories.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\t00000000000001000000000800000000000000000000000000\n",
      "1:\t00000000000000100000000000000000000000000000000000\n",
      "2:\t00000000002000200000000000200000004000000000000000\n",
      "3:\t00005000000020000000003000000000002900000000000100\n",
      "4:\t00000000000000000000400002000000000000000000000030\n",
      "5:\t00000000000200000000000052000000000000000004000000\n",
      "6:\t00000000000000000000000000000000000500000000000050\n",
      "7:\t00000000000000000010000000100000000000000000000000\n",
      "8:\t00000000000000000030000000000000000000000000010000\n",
      "9:\t00000000000600300000010000000000000000000000100003\n"
     ]
    }
   ],
   "source": [
    "matrix = np.random.choice(10, size=(num_histories, length), replace=True, p=prevalence)\n",
    "histories = []\n",
    "for idx, row in enumerate(matrix):\n",
    "    history = ''.join(list(map(str, row)))\n",
    "    print('{}:\\t{}'.format(idx, history))\n",
    "    histories.append(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol_weight_map = {str(i) : prevalence[i] for i in range(num_diseases)}\n",
    "matrices = get_all_weightedJac_matrices(histories,\n",
    "                             get_weight='linear',\n",
    "                             symbol_weight_map=symbol_weight_map,\n",
    "                             end_time=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster and plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans, spectral_clustering\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = 1.\n",
    "sim = np.exp(-beta * Jaccard / Jaccard.std())\n",
    "labels = spectral_clustering(sim, n_clusters=10, eigen_solver='arpack')\n",
    "sortedIdx = np.argsort(labels)\n",
    "Jsorted=Jaccard[sortedIdx][:,sortedIdx]\n",
    "\n",
    "sns.heatmap(Jsorted)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
