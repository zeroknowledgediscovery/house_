{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subword_subset(a,n):\n",
    "    \n",
    "    split_list = []\n",
    "    len_a = len(a)\n",
    "    for i in range(len_a):\n",
    "        delim = len_a - i\n",
    "        if delim < n:\n",
    "            break\n",
    "        split_list.append(a[i:i+n]) \n",
    "    return split_list\n",
    "\n",
    "def Omega(arr):\n",
    "\n",
    "#     t0 = time.time()\n",
    "    \n",
    "    subword_set = []\n",
    "    for i in range(1, len(arr)):\n",
    "        subword_set.extend(subword_subset(arr, i))\n",
    "    subword_set.append(arr)\n",
    "    \n",
    "#     t1 = time.time()\n",
    "#     print(\"Total time elapsed: \", t1-t0)\n",
    "    \n",
    "    return subword_set\n",
    "\n",
    "for i in range(10):\n",
    "    Omega('001010')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '0', '1', '0', '1', '0', '00', '01', '10', '01', '10', '001', '010', '101', '010', '0010', '0101', '1010', '00101', '01010', '001010']\n"
     ]
    }
   ],
   "source": [
    "Omega1 = Omega('001010')\n",
    "print(Omega1)\n",
    "Omega2 = Omega('002020')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Previous implementation of Defn 4 \n",
    "##### Note the difference in efficiency "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['34', '3', '4'], dtype='|S2')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def subword_len(a,n=1):\n",
    "    \n",
    "    split_list = [a[i:i+n] for i in range(0, len(a), 1)]\n",
    "    \n",
    "    return [x  for x in split_list if len(x) == n and len(x)>0]\n",
    "\n",
    "def subword(a):\n",
    "    #t0 = time.time()\n",
    "    try:\n",
    "        b=[a]\n",
    "        nmax=len(a)\n",
    "        for n in range(nmax):\n",
    "            c=subword_len(a,n)\n",
    "            if len(c)>0:\n",
    "                b=np.append(b,c)\n",
    "        return b\n",
    "\n",
    "    except: \n",
    "        return b\n",
    "\n",
    "    #t1 = time.time()\n",
    "    #print(\"Total time elapsed: \", t1-t0)\n",
    "\n",
    "subword('34')\n",
    "# for i in range(10):\n",
    "#     print(subword('001010'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition 5 - Jacard Similarity\n",
    "\n",
    "##### Same as prior implementation as per ishanuc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unweightedJac(S1,S2):\n",
    "    return (len(set(S1).union(S2))-len(set(S1).intersection(S2)))/(0.0+len(set(S1).union(S2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definition 6 - Weighted Jacard Sequential Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to take the sum of the weighting\n",
    "# Once this is finished, you can test individual parts then move onto putting it all together\n",
    "# def sum_weight():\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weightedJac(S1,S2, sum_weight):\n",
    "    sum_weight_union = sum_weight(list(set(S1).union(S2)))\n",
    "    return (sum_weight_union - sum_weight(list(set(S1).intersection(S2))))/(0.0+sum_weight_union)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate rando data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5, 5, 3],\n",
       "       [4, 5, 5],\n",
       "       [4, 0, 5]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3,)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.66666667, 0.75      ],\n",
       "       [0.66666667, 0.        , 0.33333333],\n",
       "       [0.75      , 0.33333333, 0.        ]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make sure to weight each sequence by population prevalence \n",
    "# (basically use the probability vector that we will be shifting around)\n",
    "# Implement the weighted Jacard Later\n",
    "\n",
    "def weight(p0_vector, i):\n",
    "    return 1/p0_vector[i]\n",
    "\n",
    "def jacMatrix(histories):\n",
    "    length = histories.shape[0]\n",
    "    jac_mat = np.zeros(shape = (length, length))\n",
    "    for i in range(length):\n",
    "        for j in range(length):\n",
    "            jac_mat[i][j] = get_unweightedJac(subword(histories[i]), subword(histories[j]))\n",
    "    return jac_mat\n",
    "                       \n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quasi Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.1, 1: 0.05, 2: 0.05, 3: 0.2, 4: 0.4, 5: 0.2}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reverse dictionary that assigns probability from original probability vector \n",
    "# to an index for use in next fn\n",
    "def p0_reverse(prob_vec):\n",
    "    rev_probs = {}\n",
    "    for i in range(prob_vec.shape[0]):\n",
    "        rev_probs[i] = prob_vec[i]\n",
    "    return rev_probs\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.2, 1: 0.4, 2: 0.4}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reverse dictionary that assigns probability to indexed history\n",
    "# we initialize this then we, in the future only edit the hist_prob_dict for future histories\n",
    "def hist_probs(histories, prob_dict):\n",
    "    hist_prob = {}\n",
    "    for i in range(histories.shape[0]):\n",
    "        hist_prob[i] = prob_dict[histories[i][0]]\n",
    "    return hist_prob\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# quasi metric matrix normalization constant\n",
    "def qm_matrix_normalization(hist_probs, i, j):\n",
    "    return .5 * (((1/hist_probs[i]) + (1/hist_probs[j])) - 2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         1.83333333 2.0625    ]\n",
      " [1.83333333 0.         0.5       ]\n",
      " [2.0625     0.5        0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# takes in jacard matrix and probabilty vector\n",
    "# returns quasi metric matrix\n",
    "# remember we have not used the weight fn, so this needs to be later implemented\n",
    "# can combine later with jac_matrix maker so we dont have to do 2 runs of matrix\n",
    "\n",
    "def qm_Matrix(histories, hist_prob):\n",
    "    length = len(hist_prob)\n",
    "    qm_mat = np.zeros(shape = (length, length))\n",
    "    for i in range(length):\n",
    "        for j in range(length):\n",
    "            qm_mat[i][j] = qm_matrix_normalization(hist_prob, i, j) * get_unweightedJac(subword(histories[i]), subword(histories[j]))\n",
    "    return qm_mat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Epsilon Neighborhood Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [0, 1, 2], 1: [0, 1, 2], 2: [0, 1, 2]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# given an epsilon, figures out which indexes are in the epsilon neighborhood of the matrix\n",
    "# basically for each row, we see which things in epsilon neighborhood then keep indexes,\n",
    "# which we then use to figure out probabilities of occurrence\n",
    "# qm matrix is gonna be symmetric, so we do calculations per column\n",
    "def epsilon_indexes(qm_matrix, epsilon):\n",
    "    col_indexes = {}\n",
    "    index_list = []\n",
    "    for i in range(qm_matrix.shape[0]):\n",
    "        for j in range(qm_matrix.shape[0]):\n",
    "            if qm_matrix[i][j] < epsilon:\n",
    "                index_list.append(j)\n",
    "        col_indexes[i] = index_list\n",
    "        index_list = []\n",
    "    return col_indexes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# updates probability of given history\n",
    "# will cache rpt probabilities later\n",
    "def hist_prob_update(histories, ep_ind, hist_probs, idx):\n",
    "    pvecs = hist_probs\n",
    "    for key in ep_ind:\n",
    "        yesval = histories[key][idx]\n",
    "        yes = 0 \n",
    "        no = 0\n",
    "        for i in range(len(ep_ind[key])):\n",
    "            histval = histories[key][ep_ind[key][i]]\n",
    "            #print(histval)\n",
    "            if yesval == histval:\n",
    "                yes = yes + 1\n",
    "            else:\n",
    "                no = no + 1\n",
    "        #print(yes,no)\n",
    "        prob = yes/(yes * 1.0 + no)\n",
    "        \n",
    "        pvecs[key] = pvecs[key] * prob\n",
    "    return pvecs\n",
    "        \n",
    "#hist_prob_update(dummy, test, hist_prob, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 5, 5, 4, 3],\n",
       "       [4, 4, 4, 1, 4],\n",
       "       [4, 3, 5, 2, 3],\n",
       "       [4, 2, 0, 0, 4],\n",
       "       [4, 5, 0, 1, 0]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# is quasi metric, have to do bigger test : \n",
    "\n",
    "p0 = np.asarray([0.1, 0.05, 0.05, 0.2, 0.4, 0.2])\n",
    "dummy = np.random.choice(np.arange(0, 6), size = (5,5),p = p0)\n",
    "dummy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Putting it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def House(histories, p0, epsilon):\n",
    "    p0_rev = p0_reverse(p0)\n",
    "    \n",
    "    hist_prob = hist_probs(histories, p0_rev)\n",
    "    print hist_prob\n",
    "    #for i in range(len(histories[0])):\n",
    "    for i in range(2):\n",
    "        qm = qm_Matrix(histories, hist_prob)\n",
    "        print(qm)\n",
    "        epsilon_indices = epsilon_indexes(qm, epsilon)\n",
    "        print(epsilon_indices)\n",
    "        hist_prob = hist_prob_update(histories, epsilon_indices, hist_prob, i)\n",
    "    return hist_prob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0.2, 1: 0.4, 2: 0.4}\n",
      "[[0.         1.83333333 2.0625    ]\n",
      " [1.83333333 0.         0.5       ]\n",
      " [2.0625     0.5        0.        ]]\n",
      "{0: [0, 1, 2], 1: [0, 1, 2], 2: [0, 1, 2]}\n",
      "[[0.         4.33333333 4.875     ]\n",
      " [4.33333333 0.         2.16666667]\n",
      " [4.875      2.16666667 0.        ]]\n",
      "{0: [0], 1: [1, 2], 2: [1, 2]}\n",
      "{0: 0.13333333333333333, 1: 0.13333333333333333, 2: 0.06666666666666667}\n"
     ]
    }
   ],
   "source": [
    "print(House(dummy, p0, 3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
